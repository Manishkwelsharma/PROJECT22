{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression - Car Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are required to model the price of cars with the predictor variable that are part of the Car Sales transactions. It will be used by the company to predict the prices for new cars coming in for sale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exploratory Data Analysis and Pre-processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"CarPrice_Assignment.csv\")\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['CarName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hello i am sivam\".split(\" \")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting company name from CarName column\n",
    "\n",
    "CompanyName = cars['CarName'].apply(lambda x : x.split(' ')[0])\n",
    "cars.insert(3,\"CompanyName\",CompanyName)\n",
    "cars.drop(['CarName'],axis=1,inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.CompanyName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fixing invalid values\n",
    "- There seems to be some spelling error in the CompanyName column.\n",
    "\n",
    "    - `maxda` = `mazda`\n",
    "    - `Nissan` = `nissan`\n",
    "    - `porsche` = `porcshce`\n",
    "    - `toyota` = `toyouta`\n",
    "    - `vokswagen` = `volkswagen` =  `vw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.CompanyName = cars.CompanyName.str.lower()\n",
    "\n",
    "def replace_name(a,b):\n",
    "    cars.CompanyName.replace(a,b,inplace=True)\n",
    "\n",
    "replace_name('alfa-romero','alfa-romeo')\n",
    "replace_name('maxda','mazda')\n",
    "replace_name('porcshce','porsche')\n",
    "replace_name('toyouta','toyota')\n",
    "replace_name('vokswagen','volkswagen')\n",
    "replace_name('vw','volkswagen')\n",
    "\n",
    "cars.CompanyName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive New field - Fuel economy\n",
    "\n",
    "cars['fueleconomy'] = (0.55 * cars['citympg']) + (0.45 * cars['highwaympg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['price'] = cars['price'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = cars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = temp.groupby(['CompanyName'])['price'].mean()\n",
    "table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the Car Companies based on avg prices of each Company.\n",
    "\n",
    "cars['price'] = cars['price'].astype('float')\n",
    "temp = cars.copy()\n",
    "table = temp.groupby(['CompanyName'])['price'].mean()\n",
    "temp = temp.merge(table.reset_index(), how='left',on='CompanyName')\n",
    "print(temp.head())\n",
    "bins = [0,10000,20000,40000]  \n",
    "cars_bin=['Budget','Medium','Highend']\n",
    "cars['carsrange'] = pd.cut(temp['price_y'],bins,right=False,labels=cars_bin)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[[\"CompanyName\",\"carsrange\"]].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the corr values of final list of variables\n",
    "cor = cars.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find High Correlations between Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the Fields with high correlation\n",
    "\n",
    "correlated_features = set()\n",
    "for i in range(len(cor.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(cor.iloc[i, j]) > 0.8:\n",
    "            colname1 = cor.columns[i]\n",
    "            colname2 = cor.columns[j]\n",
    "            print(abs(cor.iloc[i, j]), \"--\", i, '--', j, '--', colname1, '--', colname2)\n",
    "            correlated_features.add(colname1)\n",
    "            correlated_features.add(colname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cor.columns)\n",
    "print('------')\n",
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor['highwaympg']['citympg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor.loc[\"highwaympg\",'citympg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Correlation values of the High Correlated fields\n",
    "\n",
    "corh = cars[correlated_features].corr()\n",
    "corh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a Heatmap\n",
    "\n",
    "plt.figure(figsize=(14,14)) \n",
    "sns.heatmap(corh, annot=True, linewidths=.5, fmt=\".2f\", cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Create Dummy Variables for Ordinal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cars['fueltype'].unique())\n",
    "print(cars['aspiration'].unique())\n",
    "print(cars['carbody'].unique())\n",
    "print(cars['drivewheel'].unique())\n",
    "print(cars['enginetype'].unique())\n",
    "print(cars['cylindernumber'].unique())\n",
    "print(cars['carsrange'].unique())\n",
    "print(cars['fuelsystem'].unique())\n",
    "print(cars['CompanyName'].unique())\n",
    "print(cars['doornumber'].unique())\n",
    "print(cars['enginelocation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(cars['carbody'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the map function\n",
    "\n",
    "def dummies(x,df):\n",
    "    temp = pd.get_dummies(df[x], drop_first = True)\n",
    "    df = pd.concat([df, temp], axis = 1)\n",
    "    df.drop([x], axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "# Applying the function to the cars_lr\n",
    "\n",
    "cars_lr = cars\n",
    "cars_lr = dummies('fueltype',cars_lr)\n",
    "cars_lr = dummies('aspiration',cars_lr)\n",
    "cars_lr = dummies('carbody',cars_lr)\n",
    "cars_lr = dummies('drivewheel',cars_lr)\n",
    "cars_lr = dummies('enginetype',cars_lr)\n",
    "cars_lr = dummies('cylindernumber',cars_lr)\n",
    "cars_lr = dummies('carsrange',cars_lr)\n",
    "cars_lr = dummies('CompanyName',cars_lr)\n",
    "cars_lr = dummies('doornumber',cars_lr)\n",
    "cars_lr = dummies('enginelocation',cars_lr)\n",
    "cars_lr = dummies('fuelsystem',cars_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_lr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_lr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(cars_lr, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "num_vars=['wheelbase', 'carheight', 'stroke', 'curbweight', 'enginesize', 'boreratio', 'horsepower','fueleconomy','carlength','carwidth','price']\n",
    "scaler.fit(df_train[num_vars])\n",
    "scaler.transform(df_train[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "num_vars = ['wheelbase', 'carheight', 'stroke', 'curbweight', 'enginesize', 'boreratio', 'horsepower','fueleconomy','carlength','carwidth','price']\n",
    "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing data into X and y variables\n",
    "y_train = df_train.pop('price')\n",
    "X_train = df_train\n",
    "#X_train=df_train.drop([\"price\"],axis=1)\n",
    "#y_train=df_train['price']\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X,y):\n",
    "    X = sm.add_constant(X) # Adding the constant sm linear equation=y=m1x1+m2x2+....no constant\n",
    "    lm = sm.OLS(y,X).fit() # fitting the model\n",
    "    print(lm.summary())    # model summary\n",
    "    return lm\n",
    "    \n",
    "def checkVIF(X):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = X.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2)\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "    return(vif)\n",
    "def vifvalue(x):\n",
    "    col=x.columns\n",
    "    print(col.shape[0])\n",
    "    for i in range(0,col.shape[0]):\n",
    "        vif=pd.DataFrame(columns=[\"feature\",\"VIF\"])\n",
    "        x_vif=x.drop(col[i],axis=1)\n",
    "        y_vif=x[col[i]]\n",
    "        r2_value=sm.OLS(y_vif,x_vif).fit().rsquared\n",
    "        vif_value=round(1/(1-r2_value),2)\n",
    "        vif.loc[i]=[col[i],vif_value]\n",
    "    return vif.sort_values(by=\"VIF\",ascending=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifvalue(X_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the first model and clean up features with Colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.drop(\n",
    "['car_ID', 'wheelbase', 'carlength', 'compressionratio', 'horsepower', 'citympg', 'highwaympg', 'hardtop',\n",
    " 'sedan','wagon','fwd','rwd','dohcv','l','ohc','ohcf','ohcv','six','Medium',\n",
    "'audi','buick','chevrolet','dodge','honda','isuzu','jaguar','mazda','nissan','porsche','renault','saab',\n",
    " 'subaru','toyota','volkswagen','volvo','two','2bbl','4bbl','idi','mfi','mpfi','spdi'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-create the model after dropping the columns with 'P>|t|' > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_model(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Elimination using RFE (Recursive Feature Elimination)\n",
    "Recursive feature elimination (RFE) is a feature selection method that fits a model and removes the weakest feature (or features) until the specified number of features is reached. Features are ranked by the modelâ€™s coef_ or feature_importances_ attributes, and by recursively eliminating a small number of features per loop, RFE attempts to eliminate dependencies and collinearity that may exist in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train1,y_train)\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=10)\n",
    "rfe = rfe.fit(X_train1, y_train)\n",
    "dir(rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building model using statsmodel, for the detailed statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_rfe = X_train[X_train1.columns[rfe.support_]]\n",
    "X_train_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model using RFE returned Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = build_model(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-vale of `twelve` seems to be higher than the significance value of 0.05, hence dropping it as it is insignificant in presence of other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train_rfe.drop([\"twelve\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = build_model(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = sm.add_constant(X_train_new) # Adding the constant\n",
    "y_train_pred = model5.predict(X_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the test set\n",
    "\n",
    "num_vars = ['carwidth', 'curbweight', 'enginesize', 'boreratio', 'price', 'rotor', 'three', 'Highend', 'bmw', 'rear']\n",
    "\n",
    "df_test1 = pd.DataFrame(scaler.fit_transform(df_test[num_vars]), columns=num_vars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing into X and y\n",
    "\n",
    "y_test = df_test1.pop('price')\n",
    "X_test = df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use our model to make predictions.\n",
    "\n",
    "X_test_new = pd.DataFrame(sm.add_constant(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred = model5.predict(X_test_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Comparisn between Train and Test (Generalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"Test Prediction R-Sqrd: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Prediction R-Sqrd: \", r2_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference :\n",
    "\n",
    "- R-sqaured value for Training data is `92.5%` and for Test Data it is `86%`.\n",
    "- This scores are fairly decent, however, you can investigate further to achieve better generalisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly=poly.fit_transform(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_poly,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_poly=poly.transform(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final=lr.predict(X_text_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.# draw a graph representing relationship between alpha parameter and performance of model for both ridge and lasso regression.(alpha-0-10)\n",
    "2.#create model using ridge and lasso regression and compare there performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range (1,11):\n",
    "    ridge=[]\n",
    "    lasso[]\n",
    "    ridge model\n",
    "    lasso model(alpha=i)\n",
    "    fit predict\n",
    "    r2\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ridge[performance for all values of alpha]\n",
    "lasso[]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
